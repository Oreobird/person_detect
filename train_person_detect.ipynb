{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oreobird/person_detect/blob/main/train_person_detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC9d-MJG7jaQ"
      },
      "source": [
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install conda and create python3.6 env to install tensorflow==1.15.0:"
      ],
      "metadata": {
        "id": "oCnmYUrvC6Z3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZrgY8lV5vpb"
      },
      "outputs": [],
      "source": [
        "%env PYTHONPATH = # /env/python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nXQUzrR53Qt"
      },
      "outputs": [],
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!./Miniconda3-py38_4.12.0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda update conda -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5awzPgTs6PLM"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H821zT566Pzi"
      },
      "outputs": [],
      "source": [
        "!conda create -n myenv python=3.6 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FhUmkZH6VTk"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install tensorflow==1.15\n",
        "pip install contextlib2\n",
        "pip install Pillow\n",
        "pip install tf_slim\n",
        "pip install matplotlib\n",
        "pip install ipykernel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch source code"
      ],
      "metadata": {
        "id": "gwmTroXgF7_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount your google drive:"
      ],
      "metadata": {
        "id": "--EqvlCtBsuZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQEkNk4Cmc27"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPygs1AL8dNP"
      },
      "source": [
        "Clone the TensorFlow models github repository:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DO_Gad4D6_jF"
      },
      "outputs": [],
      "source": [
        "! git clone --depth=1 https://github.com/tensorflow/models.git /content/drive/MyDrive/person_detect"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone TensorFlow github repository and checkout to v1.15.0 for graph frozon:"
      ],
      "metadata": {
        "id": "nlSpX7YMCKPf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_7N_wOto_o7"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/tensorflow/tensorflow /content/drive/MyDrive/tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH5zrG7_a1zT"
      },
      "outputs": [],
      "source": [
        "! cd /content/drive/MyDrive/tensorflow && git checkout -f v1.15.0 && cd -"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify /content/drive/MyDrive/person_detect/research/slim/nets/mobilenet_v1.py to enable global average pool and use Conv2d_11_pointwise as the final endpoint:\n",
        "```\n",
        "net, end_points = mobilenet_v1_base(inputs, scope=scope, min_depth=min_depth, depth_multiplier=depth_multiplier, conv_defs=conv_defs, final_endpoint='Conv2d_11_pointwise')\n",
        "...\n",
        "mobilenet_v1_025 = wrapped_partial(mobilenet_v1, depth_multiplier=0.25, global_pool=True)\n",
        "```"
      ],
      "metadata": {
        "id": "Sq1Ho_AsOLkP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYGCTMv58mhg"
      },
      "source": [
        "## Download the Dataset\n",
        "The Visual Wake Words dataset contains images which belong to two classes: person (labelled as 1) and not-person (labelled as 0) and it is derived from the COCO dataset containing 80 categories (eg: cat, dog, umbrella, etc)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HARfyEXg6c5t"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python3 /content/drive/MyDrive/person_detect/research/slim/download_and_convert_data.py \\\n",
        "    --logtostderr \\\n",
        "    --dataset_name=visualwakewords \\\n",
        "    --dataset_dir=person_detection_dataset \\\n",
        "    --foreground_class_of_interest='person' \\\n",
        "    --small_object_area_threshold=0.005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfTz3fFz8y8P"
      },
      "source": [
        "When it's done, you'll have a set of TFRecords in the person_detection_dataset/ directory holding the labeled image information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slTA-Bcj9EzG"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v6ccsaPpSGR"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/person_detect/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgHgjMzA81l2"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHsS6cvYCpK9"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "\n",
        "python3 /content/drive/MyDrive/person_detect/research/slim/train_image_classifier.py \\\n",
        "    --clone_on_cpu=True \\\n",
        "    --alsologtostderr \\\n",
        "    --dataset_name=visualwakewords \\\n",
        "    --dataset_dir=person_detection_dataset \\\n",
        "    --dataset_split_name=train \\\n",
        "    --train_image_size=96 \\\n",
        "    --use_grayscale=True \\\n",
        "    --preprocessing_name=mobilenet_v1 \\\n",
        "    --model_name=mobilenet_v1_025 \\\n",
        "    --train_dir=/content/drive/MyDrive/person_detect/train \\\n",
        "    --save_summaries_secs=300 \\\n",
        "    --learning_rate=0.045 \\\n",
        "    --label_smoothing=0.1 \\\n",
        "    --learning_rate_decay_factor=0.98 \\\n",
        "    --num_epochs_per_decay=2.5 \\\n",
        "    --moving_average_decay=0.9999 \\\n",
        "    --batch_size=96 \\\n",
        "    --max_number_of_steps=1000000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-SEOZJA9LfO"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUyuBusP9NIl"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python3 /content/drive/MyDrive/person_detect/research/slim/eval_image_classifier.py \\\n",
        "    --alsologtostderr \\\n",
        "    --dataset_name=visualwakewords \\\n",
        "    --dataset_dir=person_detection_train \\\n",
        "    --dataset_split_name=val \\\n",
        "    --eval_image_size=96 \\\n",
        "    --use_grayscale=True \\\n",
        "    --preprocessing_name=mobilenet_v1 \\\n",
        "    --model_name=mobilenet_v1_025 \\\n",
        "    --train_dir=person_detection_train \\\n",
        "    --checkpoint_path=/content/drive/MyDrive/person_detect/train/model.ckpt-123456"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh92zWz39TOf"
      },
      "source": [
        "## Convert the TF model to a TF Lite model for Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYEcF5fF9WCm"
      },
      "source": [
        "### Generate the model graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU6n8DX-9Yv-"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python3 /content/drive/MyDrive/person_detect/research/slim/export_inference_graph.py \\\n",
        "    --alsologtostderr \\\n",
        "    --dataset_name=visualwakewords \\\n",
        "    --image_size=96 \\\n",
        "    --use_grayscale=True \\\n",
        "    --model_name=mobilenet_v1_025 \\\n",
        "    --output_file=/content/drive/MyDrive/person_detect/train/person_detection_graph.pb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryroSjgM9cWv"
      },
      "source": [
        "### Generate the frozen model graph (combine model graph and trained weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIlh8Lrg9d0F"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python3 /content/drive/MyDrive/tensorflow/tensorflow/python/tools/freeze_graph.py \\\n",
        "    --input_graph=/content/drive/MyDrive/person_detect/train/person_detection_graph.pb \\\n",
        "    --input_checkpoint=/content/drive/MyDrive/person_detect/train/model.ckpt-0 \\\n",
        "    --input_binary=true \\\n",
        "    --output_node_names=MobilenetV1/Predictions/Reshape_1,MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D \\\n",
        "    --output_graph=/content/drive/MyDrive/person_detect/train/person_detection_frozen_graph.pb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FTFnt4U9hS4"
      },
      "source": [
        "### Generate the TensorFlow Lite File with Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create file gen_quant_tflite.py and edit as:"
      ],
      "metadata": {
        "id": "kstlqhHBNLLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import io\n",
        "import PIL\n",
        "import numpy as np\n",
        "\n",
        "def representative_dataset_gen():\n",
        "\n",
        "  record_iterator = tf.python_io.tf_record_iterator(path='/content/person_detection_dataset/val.record-00000-of-00010')\n",
        "\n",
        "  for _ in range(250):\n",
        "    string_record = next(record_iterator)\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(string_record)\n",
        "    image_stream = io.BytesIO(example.features.feature['image/encoded'].bytes_list.value[0])\n",
        "    image = PIL.Image.open(image_stream)\n",
        "    image = image.resize((96, 96))\n",
        "    image = image.convert('L')\n",
        "    array = np.array(image)\n",
        "    array = np.expand_dims(array, axis=2)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    array = ((array / 127.5) - 1.0).astype(np.float32)\n",
        "    yield([array])\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_frozen_graph(\n",
        "'/content/drive/MyDrive/person_detect/train/person_detection_frozen_graph.pb',\n",
        "['input'],\n",
        "['MobilenetV1/Predictions/Reshape_1',\n",
        "'MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D'])\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_quant_model = converter.convert()\n",
        "open(\"/content/drive/MyDrive/person_detect/train/person_detection_model.tflite\", \"wb\").write(tflite_quant_model)"
      ],
      "metadata": {
        "id": "67jq3RsHNH3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run quantization:"
      ],
      "metadata": {
        "id": "ka2H9tfFNXpT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp1xAet_ed1d"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python3 /content/drive/MyDrive/person_detect/gen_quant_tflite.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W-xbjDu9mK2"
      },
      "source": [
        "### Generate the C source file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVCYrHNp9nrX",
        "outputId": "671aab77-52b9-4c1b-dc27-8eb739fc9bc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "\n",
        "# Install xxd if it is not available\n",
        "apt-get -qq install xxd\n",
        "# Save the file as a C source file\n",
        "xxd -i /content/drive/MyDrive/person_detect/train/person_detection_model.tflite > /content/drive/MyDrive/person_detect/train/person_detect_model_data.cc"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYde15ivjiRdVoBRV2CJb6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}